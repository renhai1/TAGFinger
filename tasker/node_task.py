import torch
from torch_geometric.loader import DataLoader
from utils import constraint, center_embedding, Gprompt_tuning_loss
from evaluation import GPPTEva, GNNNodeEva, GPFEva, MultiGpromptEva
from pretrain import GraphPrePrompt, NodePrePrompt, prompt_pretrain_sample
from .task import BaseTask
import time
import warnings
import numpy as np
from data import load4node, induced_graphs, graph_split, split_induced_graphs, node_sample_and_save, \
    GraphDataset
from evaluation import GpromptEva, AllInOneEva
import pickle
import os
from utils import process

warnings.filterwarnings("ignore")


# NodeTask(pre_train_model_path=args.pre_train_model_path,
#                          dataset_name=args.dataset_name, num_layer=args.num_layer,
#                          gnn_type=args.gnn_type, hid_dim=args.hid_dim, prompt_type=args.prompt_type,
#                          epochs=args.epochs, shot_num=args.shot_num, device=args.device, lr=args.lr, wd=args.decay,
#                         batch_size=args.batch_size, data=data, input_dim=input_dim, output_dim=output_dim,
#                          graphs_list=graphs_list)
class NodeTask(BaseTask):
    def __init__(self, data, input_dim, output_dim, task_num=5, graphs_list=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.task_type = 'NodeTask'
        self.task_num = task_num  # å¢åŠ task_numçš„å‚æ•°ï¼Œæ§åˆ¶é‡å¤æ•°é‡ï¼Œé»˜è®¤ä¸º5
        if self.prompt_type == 'MultiGprompt':
            self.load_multigprompt_data()
        else:
            self.data = data
            if self.dataset_name == 'ogbn-arxiv':
                self.data.y = self.data.y.squeeze()
            self.input_dim = input_dim
            self.output_dim = output_dim
            self.graphs_list = graphs_list

        self.create_few_data_folder()

    def create_few_data_folder(self):
        # åˆ›å»ºæ–‡ä»¶å¤¹å¹¶ä¿å­˜æ•°æ®
        k = self.shot_num  # shot_num å¯å˜
        task_num = self.task_num  # task_num å¯å˜
        for k in range(1, task_num + 1):
            k_shot_folder = './Experiment/sample_data/Node/' + self.dataset_name + '/' + str(k) + '_shot'
            os.makedirs(k_shot_folder, exist_ok=True)

            for i in range(1, task_num + 1):
                folder = os.path.join(k_shot_folder, str(i))
                if not os.path.exists(folder):
                    os.makedirs(folder)
                    node_sample_and_save(self.data, k, folder, self.output_dim)
                    print(str(k) + ' shot ' + str(i) + ' th is saved!!')

    def load_multigprompt_data(self):
        adj, features, labels = process.load_data(self.dataset_name)
        # adj, features, labels = process.load_data(self.dataset_name)
        self.input_dim = features.shape[1]
        self.output_dim = labels.shape[1]
        print('a', self.output_dim)
        features, _ = process.preprocess_features(features)
        self.sp_adj = process.sparse_mx_to_torch_sparse_tensor(adj).to(self.device)
        self.labels = torch.FloatTensor(labels[np.newaxis])
        self.features = torch.FloatTensor(features[np.newaxis]).to(self.device)
        # print("labels",labels)
        print("adj", self.sp_adj.shape)
        print("feature", features.shape)

    def load_induced_graph(self):
        smallest_size = 5  # é»˜è®¤ä¸º5
        if self.dataset_name in ['ENZYMES', 'PROTEINS']:
            smallest_size = 1
        if self.dataset_name == 'PubMed':
            smallest_size = 8
        folder_path = './Experiment/induced_graph/' + self.dataset_name
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)

        file_path = folder_path + '/induced_graph_min{}_max300.pkl'.format(smallest_size)
        if os.path.exists(file_path):
            with open(file_path, 'rb') as f:
                graphs_list = pickle.load(f)
        else:
            print('Begin split_induced_graphs.')
            split_induced_graphs(self.data, folder_path, self.device, smallest_size=smallest_size, largest_size=300)
            with open(file_path, 'rb') as f:
                graphs_list = pickle.load(f)
        self.graphs_list = []
        for i in range(len(graphs_list)):
            graph = graphs_list[i].to(self.device)
            self.graphs_list.append(graph)

    def load_data(self):
        self.data, self.input_dim, self.output_dim = load4node(self.dataset_name)

    def train(self, data, train_idx):
        self.gnn.train()
        self.answering.train()
        self.optimizer.zero_grad()
        out = self.gnn(data.x, data.edge_index, batch=None)
        out = self.answering(out)
        loss = self.criterion(out[train_idx], data.y[train_idx])
        loss.backward()
        self.optimizer.step()
        return loss.item()

    def GPPTtrain(self, data, train_idx):
        self.prompt.train()
        node_embedding = self.gnn(data.x, data.edge_index)
        out = self.prompt(node_embedding, data.edge_index)
        loss = self.criterion(out[train_idx], data.y[train_idx])
        loss = loss + 0.001 * constraint(self.device, self.prompt.get_TaskToken())
        self.pg_opi.zero_grad()
        loss.backward()
        self.pg_opi.step()
        mid_h = self.prompt.get_mid_h()
        self.prompt.update_StructureToken_weight(mid_h)
        return loss.item()

    def MultiGpromptTrain(self, pretrain_embs, train_lbls, train_idx):
        self.DownPrompt.train()
        self.optimizer.zero_grad()
        prompt_feature = self.feature_prompt(self.features)
        # prompt_feature = self.feature_prompt(self.data.x)
        # embeds1 = self.gnn(prompt_feature, self.data.edge_index)
        embeds1 = self.Preprompt.gcn(prompt_feature, self.sp_adj, True, False)
        pretrain_embs1 = embeds1[0, train_idx]
        logits = self.DownPrompt(pretrain_embs, pretrain_embs1, train_lbls, 1).float().to(self.device)
        loss = self.criterion(logits, train_lbls)
        loss.backward(retain_graph=True)
        self.optimizer.step()
        return loss.item()

    def SUPTtrain(self, data):
        self.gnn.train()
        self.optimizer.zero_grad()
        data.x = self.prompt.add(data.x)
        out = self.gnn(data.x, data.edge_index, batch=None)
        out = self.answering(out)
        loss = self.criterion(out[data.train_mask], data.y[data.train_mask])
        orth_loss = self.prompt.orthogonal_loss()
        loss += orth_loss
        loss.backward()
        self.optimizer.step()
        return loss

    def GPFTrain(self, train_loader):
        self.prompt.train()
        total_loss = 0.0
        for batch in train_loader:
            self.optimizer.zero_grad()
            batch = batch.to(self.device)
            batch.x = self.prompt.add(batch.x)
            out = self.gnn(batch.x, batch.edge_index, batch.batch, prompt=self.prompt, prompt_type=self.prompt_type)
            out = self.answering(out)
            loss = self.criterion(out, batch.y)
            loss.backward()
            self.optimizer.step()
            total_loss += loss.item()
        return total_loss / len(train_loader)

    def AllInOneTrain(self, train_loader, answer_epoch=1, prompt_epoch=1):
        # we update answering and prompt alternately.
        # tune task head
        self.answering.train()
        self.prompt.eval()
        self.gnn.eval()
        for epoch in range(1, answer_epoch + 1):
            answer_loss = self.prompt.Tune(train_loader, self.gnn, self.answering, self.criterion, self.answer_opi,
                                           self.device)
            print(("frozen gnn | frozen prompt | *tune answering function... {}/{} ,loss: {:.4f} ".format(epoch,
                                                                                                          answer_epoch,
                                                                                                          answer_loss)))

        # tune prompt
        self.answering.eval()
        self.prompt.train()
        for epoch in range(1, prompt_epoch + 1):
            pg_loss = self.prompt.Tune(train_loader, self.gnn, self.answering, self.criterion, self.pg_opi, self.device)
            print(("frozen gnn | *tune prompt |frozen answering function... {}/{} ,loss: {:.4f} ".format(epoch,
                                                                                                         prompt_epoch,
                                                                                                         pg_loss)))

        # return pg_loss
        return answer_loss

    def GpromptTrain(self, train_loader):
        self.prompt.train()
        total_loss = 0.0
        accumulated_centers = None
        accumulated_counts = None
        for batch in train_loader:
            self.pg_opi.zero_grad()
            batch = batch.to(self.device)
            out = self.gnn(batch.x, batch.edge_index, batch.batch, prompt=self.prompt, prompt_type='Gprompt')
            # out = sğ‘¡,ğ‘¥ = ReadOut({pğ‘¡ âŠ™ hğ‘£ : ğ‘£ âˆˆ ğ‘‰ (ğ‘†ğ‘¥)}),
            center, class_counts = center_embedding(out, batch.y, self.output_dim)
            # ç´¯ç§¯ä¸­å¿ƒå‘é‡å’Œæ ·æœ¬æ•°
            if accumulated_centers is None:
                accumulated_centers = center
                accumulated_counts = class_counts
            else:
                accumulated_centers += center * class_counts
                accumulated_counts += class_counts
            criterion = Gprompt_tuning_loss()
            loss = criterion(out, center, batch.y)
            loss.backward()
            self.pg_opi.step()
            total_loss += loss.item()
        # è®¡ç®—åŠ æƒå¹³å‡ä¸­å¿ƒå‘é‡
        mean_centers = accumulated_centers / accumulated_counts

        return total_loss / len(train_loader), mean_centers

    def run(self):
        test_accs = []
        f1s = []
        rocs = []
        prcs = []
        batch_best_loss = []
        if self.prompt_type == 'All-in-one':
            self.answer_epoch = 50
            self.prompt_epoch = 50
            self.epochs = int(self.epochs / self.answer_epoch)
        for i in range(1, self.task_num + 1):
            sample_data_foler_path = "./Experiment/sample_data/Node/{}/{}_shot/{}".format(self.dataset_name,
                                                                                          self.shot_num, i)
            if not os.path.exists(sample_data_foler_path):
                print(
                    f"Warning! Failed to find sample_data for shot {self.shot_num}, id {i}, path: {sample_data_foler_path}, skipping...")
                continue

            self.initialize_gnn()
            # åˆ†ç±»å™¨
            self.answering = torch.nn.Sequential(torch.nn.Linear(self.hid_dim, self.output_dim),
                                                 torch.nn.Softmax(dim=1)).to(self.device)
            self.initialize_prompt()
            self.initialize_optimizer()

            # æ•°æ®åŠ è½½
            idx_train = torch.load(f"{sample_data_foler_path}/train_idx.pt").type(torch.long).to(self.device)
            print('idx_train', idx_train)
            train_lbls = torch.load(f"{sample_data_foler_path}/train_labels.pt").type(torch.long).squeeze().to(
                self.device)
            print("true", i, train_lbls)
            idx_test = torch.load(f"{sample_data_foler_path}/test_idx.pt").type(torch.long).to(self.device)
            test_lbls = torch.load(f"{sample_data_foler_path}/test_labels.pt").type(torch.long).squeeze().to(
                self.device)

            # GPPT prompt initialtion
            if self.prompt_type == 'GPPT':
                node_embedding = self.gnn(self.data.x, self.data.edge_index)
                self.prompt.weigth_init(node_embedding, self.data.edge_index, self.data.y, idx_train)

            if self.prompt_type == 'MultiGprompt':
                embeds, _ = self.Preprompt.embed(self.features, self.sp_adj, True, None, False)
                pretrain_embs = embeds[0, idx_train]
                test_embs = embeds[0, idx_test]

            patience = 20
            best = 1e9
            cnt_wait = 0
            best_loss = 1e9

            for epoch in range(1, self.epochs):

                if self.prompt_type in ['Gprompt', 'All-in-one', 'GPF', 'GPF-plus']:
                    train_graphs = []
                    test_graphs = []
                    # self.graphs_list.to(self.device)
                    print('distinguishing the train dataset and test dataset...')
                    for graph in self.graphs_list:
                        if graph.index in idx_train:
                            train_graphs.append(graph)
                        elif graph.index in idx_test:
                            test_graphs.append(graph)
                    print('Done!!!')

                    train_dataset = GraphDataset(train_graphs)
                    test_dataset = GraphDataset(test_graphs)
                    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
                    train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
                    test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)
                    print("prepare induce graph data is finished!")

                # å¤–å¾ªç¯ä¼˜åŒ–åŒä½ç´  prompt åœæ­¢ä¼˜åŒ– ä¸»è¦æŸå¤±åŒ…æ‹¬ æº¯æºæŸå¤± åµŒå…¥è¡¨ç¤ºçš„ä½™å¼¦ç›¸ä¼¼æ€§æŸå¤±ã€åˆ†å¸ƒå·®å¼‚æŸå¤±  ä»»åŠ¡ï¼šè®­ç»ƒæµæ¨¡å‹ä¼°è®¡é«˜æ–¯åˆ†å¸ƒ è®¡ç®—åˆ†å¸ƒå·®å¼‚ è®¾è®¡æŸå¤±å‡½æ•°
                # æ ¹æ®è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç´¢å¼•åŠ è½½å¯¹åº”çš„è¯±å¯¼å­å›¾ æŠŠç”Ÿæˆçš„åŒä½ç´ å­å›¾åŠ å…¥åˆ°å¯¹åº”çš„è¯±å¯¼å­å›¾å½“ä¸­
                # è®­ç»ƒMLPç”ŸæˆåŒä½ç´ å­å›¾
                # å°†å­å›¾æ’å…¥åˆ°è®­ç»ƒé›†ä¸­

                #1ã€åˆ©ç”¨MLPè®­ç»ƒè§¦å‘å™¨

                #2ã€åˆ©ç”¨ä½™å¼¦ç›¸ä¼¼æ€§è®¡ç®—åµŒå…¥ç›¸ä¼¼æ€§æŸå¤±

                #3ã€åˆ©ç”¨æµæ¨¡å‹è®¡ç®—åˆ†å¸ƒå·®å¼‚æŸå¤±

                # å°†ä¸‰ä¸ªæŸå¤±æ±‚å’Œ ä¼˜åŒ–æŸå¤±


                # å†…å¾ªç¯ä¼˜åŒ–æç¤º promptä¼˜åŒ– è§¦å‘å™¨åœæ­¢ä¼˜åŒ–  æŸå¤±åŒ…æ‹¬ æ­£ç¡®åˆ†ç±»æŸå¤± ä»¥åŠä»£ç†æç¤ºå’Œæ‰°åŠ¨æç¤ºçš„ä½™å¼¦ç›¸ä¼¼æ€§æŸå¤± ä»»åŠ¡ä¿®æ”¹ LOSSå‡½æ•° å¢åŠ ç›¸ä¼¼æ€§æŸå¤±
                for epoch in range(1, self.epochs):
                    t0 = time.time()
                    if self.prompt_type == 'None':
                        loss = self.train(self.data, idx_train)
                    elif self.prompt_type == 'GPPT':
                        loss = self.GPPTtrain(self.data, idx_train)
                    elif self.prompt_type == 'All-in-one':
                        loss = self.AllInOneTrain(train_loader, self.answer_epoch, self.prompt_epoch)
                    elif self.prompt_type in ['GPF', 'GPF-plus']:
                        loss = self.GPFTrain(train_loader)
                    elif self.prompt_type == 'Gprompt':
                        loss, center = self.GpromptTrain(train_loader)
                    elif self.prompt_type == 'MultiGprompt':
                        loss = self.MultiGpromptTrain(pretrain_embs, train_lbls, idx_train)

                    if loss < best:
                        best = loss
                        # best_t = epoch
                        cnt_wait = 0
                        # torch.save(model.state_dict(), args.save_name)
                    else:
                        cnt_wait += 1
                        if cnt_wait == patience:
                            print('-' * 100)
                            print('Early stopping at ' + str(epoch) + ' eopch!')
                            break

                    print("Epoch {:03d} |  Time(s) {:.4f} | Loss {:.4f}  ".format(epoch, time.time() - t0, loss))
                import math
                if not math.isnan(loss):
                    batch_best_loss.append(loss)

                    if self.prompt_type == 'None':
                        test_acc, f1, roc, prc = GNNNodeEva(self.data, idx_test, self.gnn, self.answering,
                                                            self.output_dim,
                                                            self.device)
                    elif self.prompt_type == 'GPPT':
                        test_acc, f1, roc, prc = GPPTEva(self.data, idx_test, self.gnn, self.prompt, self.output_dim,
                                                         self.device)
                    elif self.prompt_type == 'All-in-one':
                        test_acc, f1, roc, prc = AllInOneEva(test_loader, self.prompt, self.gnn, self.answering,
                                                             self.output_dim, self.device)
                    elif self.prompt_type in ['GPF', 'GPF-plus']:
                        test_acc, f1, roc, prc = GPFEva(test_loader, self.gnn, self.prompt, self.answering,
                                                        self.output_dim,
                                                        self.device)
                    elif self.prompt_type == 'Gprompt':
                        test_acc, f1, roc, prc = GpromptEva(test_loader, self.gnn, self.prompt, center, self.output_dim,
                                                            self.device)
                    elif self.prompt_type == 'MultiGprompt':
                        prompt_feature = self.feature_prompt(self.features)
                        test_acc, f1, roc, prc = MultiGpromptEva(test_embs, test_lbls, idx_test, prompt_feature,
                                                                 self.Preprompt, self.DownPrompt, self.sp_adj,
                                                                 self.output_dim, self.device)

                    print(
                        f"Final True Accuracy: {test_acc:.4f} | Macro F1 Score: {f1:.4f} | AUROC: {roc:.4f} | AUPRC: {prc:.4f}")
                    print("best_loss", batch_best_loss)
                    test_accs.append(test_acc)
                    f1s.append(f1)
                    rocs.append(roc)
                    prcs.append(prc)

                mean_test_acc = np.mean(test_accs)
                std_test_acc = np.std(test_accs)
                mean_f1 = np.mean(f1s)
                std_f1 = np.std(f1s)
                mean_roc = np.mean(rocs)
                std_roc = np.std(rocs)
                mean_prc = np.mean(prcs)
                std_prc = np.std(prcs)
                print('Acc List', test_accs)  # è¾“å‡ºæ‰€æœ‰æµ‹è¯•çš„Accç»“æœ
                print(" Final best | test Accuracy {:.4f}Â±{:.4f}(std)".format(mean_test_acc, std_test_acc))
                print(" Final best | test F1 {:.4f}Â±{:.4f}(std)".format(mean_f1, std_f1))
                print(" Final best | AUROC {:.4f}Â±{:.4f}(std)".format(mean_roc, std_roc))
                print(" Final best | AUPRC {:.4f}Â±{:.4f}(std)".format(mean_prc, std_prc))

                print(self.pre_train_type, self.gnn_type, self.prompt_type, "Node Task completed")
                mean_best = np.mean(batch_best_loss)

                return mean_best, mean_test_acc, std_test_acc, mean_f1, std_f1, mean_roc, std_roc, mean_prc, std_prc
